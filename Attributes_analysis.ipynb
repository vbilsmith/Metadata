{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0fd4564-f035-43a5-8c6b-17a5150fa61f",
   "metadata": {},
   "source": [
    "show attributes counts for both human and mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83d02f4-db48-4e9b-9e7c-25e7b9ad8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db0e7da-46e4-45ea-af86-3c285fb30201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_GSE():\n",
    "    GREIN_data = pd.read_csv(\"data/GREIN_data.csv\")\n",
    "    GREIN_data = GREIN_data[GREIN_data.Species != 'Rattus norvegicus'] #drop brown rat\n",
    "    GREIN_human = GREIN_data[GREIN_data.Species == 'Homo sapiens']\n",
    "    GREIN_mouse = GREIN_data[GREIN_data.Species == 'Mus musculus']\n",
    "    \n",
    "    GSE_human = GREIN_human['GEO accession'].tolist()\n",
    "    GSE_mouse = GREIN_mouse['GEO accession'].tolist()\n",
    "    \n",
    "    return GSE_human, GSE_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee4e6ae6-a309-4dc3-9ac3-01bb81670a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(geo_id):\n",
    "    return f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={geo_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef994eb-d50e-4af8-b838-fd3191406dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.text if response.status_code == 200 else f\"Failed to retrieve the page. Status code: {response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee60ea3e-5aa8-49e1-a51f-bec077eb2cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_geo_data(geo_id):\n",
    "    url = get_url(geo_id)\n",
    "    page_content = fetch_page(url)\n",
    "    \n",
    "    if not isinstance(page_content, str):\n",
    "        return page_content\n",
    "\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    gsm_links = soup.find_all('a', href=lambda href: href and href.startswith('/geo/query/acc.cgi?acc=GSM'))\n",
    "    gsm_values = [link.text for link in gsm_links]\n",
    "\n",
    "    # Store GSM values with their corresponding GSE (geo_id) in a dictionary\n",
    "    gse_gsm_dict = {geo_id: gsm_values}\n",
    "\n",
    "    return gse_gsm_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29178ba-177f-4663-837a-071f85a1f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_characteristics(geo_id):\n",
    "    url = get_url(geo_id)\n",
    "    page_content = fetch_page(url)\n",
    "    \n",
    "    if not isinstance(page_content, str):\n",
    "        return page_content\n",
    "\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    characteristics_label = soup.find('td', text='Characteristics')\n",
    "\n",
    "    if characteristics_label:\n",
    "        characteristics_content = characteristics_label.find_next_sibling('td')\n",
    "        return str(characteristics_content)\n",
    "\n",
    "    return f\"Failed to find Characteristics for {geo_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc46524-d74a-41ed-94e5-7754af17d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_characteristics(input_str):\n",
    "    input_str = re.sub(r'<td[^>]*>', '', input_str)\n",
    "    pattern = r'(\\w+): ([^<]+)'\n",
    "    matches = re.findall(pattern, input_str)\n",
    "    \n",
    "    characteristics_dictionary = dict(matches)\n",
    "    \n",
    "    return characteristics_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc80ec7-8b9d-457f-b499-a5fa5023fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gsm(gsm):\n",
    "    characteristics_string = scrape_characteristics(gsm)\n",
    "    characteristics_dictionary = extract_characteristics(characteristics_string)\n",
    "    return gsm, characteristics_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7523ca-f2ea-428f-a4c2-8db5e220b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    GSEs_human = import_GSE()[0]\n",
    "\n",
    "    GSM_human = {}\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Use executor.map to parallelize the execution of scrape_geo_data\n",
    "#         gse_gsm_dicts = list(tqdm(executor.map(scrape_geo_data, GSEs_human), total=len(GSEs_human), desc=\"Scraping GEO Data\"))\n",
    "        \n",
    "        gse_gsm_dicts = list(tqdm(executor.map(scrape_geo_data, GSEs_human[:10]), total=len(GSEs_human[:10]), desc=\"Scraping GEO Data\"))\n",
    "        \n",
    "        for gse_gsm_dict in gse_gsm_dicts:\n",
    "            GSM_human.update(gse_gsm_dict)\n",
    "\n",
    "    results = {}\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Use executor.map to parallelize the execution of process_gsm\n",
    "        gsm_characteristics = list(tqdm(executor.map(process_gsm, (gsm for gsm_list in GSM_human.values() for gsm in gsm_list)), total=len(GSM_human), desc=\"Processing GSM Characteristics\"))\n",
    "\n",
    "        for gsm, characteristics_dictionary in gsm_characteristics:\n",
    "            results[gsm] = characteristics_dictionary\n",
    "\n",
    "    characteristics_dict = {}\n",
    "    for gsm_id, characteristics in results.items():\n",
    "        for gse_id, gsm_list in GSM_human.items():\n",
    "            if gsm_id in gsm_list:\n",
    "                if gse_id not in characteristics_dict:\n",
    "                    characteristics_dict[gse_id] = {}\n",
    "                characteristics_dict[gse_id][gsm_id] = characteristics\n",
    "\n",
    "    # Store the dictionary in a JSON file\n",
    "    with open('data/charateristics_human.json', 'w') as json_file:\n",
    "        json.dump(characteristics_dict, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c3df2f-2ee6-4458-a490-2bb0dc3a453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping GEO Data: 100%|██████████| 10/10 [00:00<00:00, 15.19it/s]\n",
      "Processing GSM Characteristics:   0%|          | 0/10 [00:00<?, ?it/s]/tmp/ipykernel_1596651/3920716366.py:9: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  characteristics_label = soup.find('td', text='Characteristics')\n",
      "Processing GSM Characteristics: 325it [00:12, 25.35it/s]                      \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "79fb5a3d-ab23-4019-9b5f-bac0eda511ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_label_content(soup, label_text):\n",
    "    label = soup.find('td', text=label_text)\n",
    "    if label:\n",
    "        content = label.find_next_sibling('td').get_text()\n",
    "    else:\n",
    "        content = f\"{label_text} not found on the page.\"\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6b60924b-b68d-437c-8487-44b3bb04eb16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_metadata(geo_id):\n",
    "    url = f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={geo_id}\"\n",
    "\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "\n",
    "        if response.status_code == 200:\n",
    "            soup = BeautifulSoup(response.text, 'html.parser')\n",
    "            \n",
    "            metadata = {\n",
    "                'Title': extract_label_content(soup, 'Title'),\n",
    "                'Experiment type': extract_label_content(soup, 'Experiment type'),\n",
    "                'Organism': extract_label_content(soup, 'Organism'),\n",
    "                'Summary': extract_label_content(soup, 'Summary'),\n",
    "                'Overall design': extract_label_content(soup, 'Overall design'),\n",
    "                'SRA': extract_label_content(soup, 'SRA'),\n",
    "                'Samples': [] \n",
    "            }\n",
    "\n",
    "           # Find all <a> tags with href attributes containing \"GSM\"\n",
    "            gsm_links = soup.find_all('a', href=lambda href: href and href.startswith('/geo/query/acc.cgi?acc=GSM'))\n",
    "\n",
    "            gsm_values = [link.text for link in gsm_links]\n",
    "\n",
    "           \n",
    "            metadata['Samples'] = gsm_values\n",
    "            \n",
    "            platforms_label = soup.find('td', text=re.compile(r'Platforms \\(\\d+\\)'))\n",
    "            if platforms_label:\n",
    "                metadata['Platforms'] = platforms_label.find_next_sibling('td').get_text()\n",
    "            else:\n",
    "                metadata['Platforms'] = \"Platforms not found on the page.\"\n",
    "\n",
    "            return metadata\n",
    "\n",
    "        else:\n",
    "            return f\"Failed to retrieve the page. Status code: {response.status_code}\"\n",
    "\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b04819d3-b00c-4694-b764-aac417cbf704",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_metadata_parallel(gse_values):\n",
    "    metadata_dict = {}\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        metadata_list = list(tqdm(executor.map(scrape_metadata, gse_values), total=len(gse_values), desc=\"Fetching Metadata\"))\n",
    "        metadata_dict = dict(zip(gse_values, metadata_list))\n",
    "    return metadata_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b033d47c-a509-4110-8671-46ba0e0059dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "metadata: {'Title': 'Human TFIIH kinase CDK7 regulates transcription-associated epigenetic modification', 'Experiment type': 'Expression profiling by high throughput sequencingGenome binding/occupancy profiling by high throughput sequencing', 'Organism': 'Homo sapiens', 'Summary': 'CDK7 phosphorylates the RNA polymerase II (pol II) CTD and activates the P-TEFb- associated kinase, CDK9, but its regulatory roles remain obscure. Using human CDK7 analog-sensitive (CDK7as) cells, we observed reduced capping enzyme recruitment, increased pol II promoter-proximal pausing, and defective termination at gene 3\\'-ends upon CDK7 inhibition. We also found that CDK7 regulates chromatin modifications downstream of transcription start sites. H3K4me3 spreading was restricted at gene 5\\'-ends and H3K36me3 was displaced toward gene 3\\'-ends in CDK7as cells. Together, these results implicate a CDK7-dependent \"CTD code\" that regulates epigenetic marks in addition to RNA processing and pol II pausing.', 'Overall design': 'WT and analogue sensitive Cdk7as mutant cells were treated with the ATP analogue NM-PP1 that specifically inhibits the Cdk7as mutant kinase. Using ChIP-seq and RNA-seq we tested the effects of Cdk7 inactivation on pol II distribution along genes, CTD Ser2 and Ser5 phosphorylation, capping enzyme recruitment, histone H3K4 and H3K36 methylation and mRNA expression', 'SRA': 'SRP109292', 'Samples': ['GSM2670975', 'GSM2670976', 'GSM2670977', 'GSM2670978', 'GSM2670979', 'GSM2670980', 'GSM2670981', 'GSM2670982', 'GSM2670983', 'GSM2670984', 'GSM2670985', 'GSM2670986', 'GSM2670987', 'GSM2670988', 'GSM2670989', 'GSM2670990', 'GSM2670991', 'GSM2670992', 'GSM2670993', 'GSM2670994', 'GSM2670995', 'GSM2670996', 'GSM2670997', 'GSM2670998', 'GSM2670999', 'GSM2671000', 'GSM2671001', 'GSM2671002', 'GSM2671003', 'GSM2671004', 'GSM2671005', 'GSM2671006', 'GSM2722166', 'GSM2722167'], 'Platforms': 'GPL20301\\nIllumina HiSeq 4000 (Homo sapiens)\\n\\nGPL21290\\nIllumina HiSeq 3000 (Homo sapiens)\\n\\n'}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1596651/2872315753.py:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label = soup.find('td', text=label_text)\n",
      "/tmp/ipykernel_1596651/1157152171.py:28: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  platforms_label = soup.find('td', text=re.compile(r'Platforms \\(\\d+\\)'))\n"
     ]
    }
   ],
   "source": [
    "geo_id = \"GSE100040\"\n",
    "metadata = scrape_metadata(geo_id)\n",
    "print(\"metadata:\", metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "20ceb3f4-706c-4fc6-98ab-bd6decd8d8ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:   0%|          | 0/4066 [00:00<?, ?it/s]/tmp/ipykernel_1596651/2872315753.py:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label = soup.find('td', text=label_text)\n",
      "/tmp/ipykernel_1596651/1157152171.py:28: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  platforms_label = soup.find('td', text=re.compile(r'Platforms \\(\\d+\\)'))\n",
      "Fetching Metadata: 100%|██████████| 4066/4066 [04:53<00:00, 13.87it/s]\n"
     ]
    }
   ],
   "source": [
    "GSEs_mouse = import_GSE()[1]\n",
    "\n",
    "metadata_dict_mouse = fetch_metadata_parallel(GSEs_mouse)\n",
    "\n",
    "# Save metadata as JSON file\n",
    "with open('data/metadata_mouse.json', 'w') as json_file:\n",
    "    json.dump(metadata_dict_mouse, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "98d5cede-811f-42a2-8ac6-a9501e7cd51d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching Metadata:   0%|          | 0/3395 [00:00<?, ?it/s]/tmp/ipykernel_1596651/2872315753.py:2: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  label = soup.find('td', text=label_text)\n",
      "/tmp/ipykernel_1596651/1157152171.py:28: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  platforms_label = soup.find('td', text=re.compile(r'Platforms \\(\\d+\\)'))\n",
      "Fetching Metadata: 100%|██████████| 3395/3395 [06:55<00:00,  8.16it/s]  \n"
     ]
    }
   ],
   "source": [
    "GSEs_human = import_GSE()[0]\n",
    "\n",
    "metadata_dict = fetch_metadata_parallel(GSEs_human)\n",
    "\n",
    "# Save metadata as JSON file\n",
    "with open('data/metadata_human.json', 'w') as json_file:\n",
    "    json.dump(metadata_dict, json_file)\n",
    "        \n",
    "# for gse_id, metadata in metadata_dict.items():\n",
    "#     print(f\"Metadata for {gse_id}:\", metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7ef3ba-afbf-4f81-a4bd-a66d2ef5a666",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
