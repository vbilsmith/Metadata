{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0fd4564-f035-43a5-8c6b-17a5150fa61f",
   "metadata": {},
   "source": [
    "show attributes counts for both human and mouse, scale up to 100 GSEs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b83d02f4-db48-4e9b-9e7c-25e7b9ad8454",
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import csv\n",
    "import re\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1db0e7da-46e4-45ea-af86-3c285fb30201",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_GSE():\n",
    "    GREIN_data = pd.read_csv(\"data/GREIN_data.csv\")\n",
    "    GREIN_data = GREIN_data[GREIN_data.Species != 'Rattus norvegicus'] #drop brown rat\n",
    "    GREIN_human = GREIN_data[GREIN_data.Species == 'Homo sapiens']\n",
    "    GREIN_mouse = GREIN_data[GREIN_data.Species == 'Mus musculus']\n",
    "    \n",
    "    GSE_human = GREIN_human['GEO accession'].tolist()\n",
    "    GSE_mouse = GREIN_mouse['GEO accession'].tolist()\n",
    "    \n",
    "    return GSE_human, GSE_mouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ee4e6ae6-a309-4dc3-9ac3-01bb81670a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_url(geo_id):\n",
    "    return f\"https://www.ncbi.nlm.nih.gov/geo/query/acc.cgi?acc={geo_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3ef994eb-d50e-4af8-b838-fd3191406dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_page(url):\n",
    "    try:\n",
    "        response = requests.get(url)\n",
    "        return response.text if response.status_code == 200 else f\"Failed to retrieve the page. Status code: {response.status_code}\"\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        return f\"Error: {e}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee60ea3e-5aa8-49e1-a51f-bec077eb2cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_geo_data(geo_id):\n",
    "    url = get_url(geo_id)\n",
    "    page_content = fetch_page(url)\n",
    "    \n",
    "    if not isinstance(page_content, str):\n",
    "        return page_content\n",
    "\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    gsm_links = soup.find_all('a', href=lambda href: href and href.startswith('/geo/query/acc.cgi?acc=GSM'))\n",
    "    gsm_values = [link.text for link in gsm_links]\n",
    "\n",
    "    # Store GSM values with their corresponding GSE (geo_id) in a dictionary\n",
    "    gse_gsm_dict = {geo_id: gsm_values}\n",
    "\n",
    "    return gse_gsm_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a29178ba-177f-4663-837a-071f85a1f849",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_characteristics(geo_id):\n",
    "    url = get_url(geo_id)\n",
    "    page_content = fetch_page(url)\n",
    "    \n",
    "    if not isinstance(page_content, str):\n",
    "        return page_content\n",
    "\n",
    "    soup = BeautifulSoup(page_content, 'html.parser')\n",
    "    characteristics_label = soup.find('td', text='Characteristics')\n",
    "\n",
    "    if characteristics_label:\n",
    "        characteristics_content = characteristics_label.find_next_sibling('td')\n",
    "        return str(characteristics_content)\n",
    "\n",
    "    return f\"Failed to find Characteristics for {geo_id}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fc46524-d74a-41ed-94e5-7754af17d05f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_characteristics(input_str):\n",
    "    input_str = re.sub(r'<td[^>]*>', '', input_str)\n",
    "    pattern = r'(\\w+): ([^<]+)'\n",
    "    matches = re.findall(pattern, input_str)\n",
    "    \n",
    "    characteristics_dictionary = dict(matches)\n",
    "    \n",
    "    return characteristics_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8cc80ec7-8b9d-457f-b499-a5fa5023fe23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_gsm(gsm):\n",
    "    characteristics_string = scrape_characteristics(gsm)\n",
    "    characteristics_dictionary = extract_characteristics(characteristics_string)\n",
    "    return gsm, characteristics_dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7f7523ca-f2ea-428f-a4c2-8db5e220b13e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    # Specify the device (CPU or GPU)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    GSEs_human = import_GSE()[0]\n",
    "\n",
    "    GSM_human = {}\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Use executor.map to parallelize the execution of scrape_geo_data\n",
    "#         gse_gsm_dicts = list(tqdm(executor.map(scrape_geo_data, GSEs_human), total=len(GSEs_human), desc=\"Scraping GEO Data\"))\n",
    "        \n",
    "        gse_gsm_dicts = list(tqdm(executor.map(scrape_geo_data, GSEs_human[:100]), total=len(GSEs_human[:100]), desc=\"Scraping GEO Data\"))\n",
    "        \n",
    "        for gse_gsm_dict in gse_gsm_dicts:\n",
    "            GSM_human.update(gse_gsm_dict)\n",
    "\n",
    "    results = {}\n",
    "    with concurrent.futures.ThreadPoolExecutor() as executor:\n",
    "        # Use executor.map to parallelize the execution of process_gsm\n",
    "        gsm_characteristics = list(tqdm(executor.map(process_gsm, (gsm for gsm_list in GSM_human.values() for gsm in gsm_list)), total=len(GSM_human), desc=\"Processing GSM Characteristics\"))\n",
    "\n",
    "        for gsm, characteristics_dictionary in gsm_characteristics:\n",
    "            results[gsm] = characteristics_dictionary\n",
    "\n",
    "    characteristics_dict = {}\n",
    "    for gsm_id, characteristics in results.items():\n",
    "        for gse_id, gsm_list in GSM_human.items():\n",
    "            if gsm_id in gsm_list:\n",
    "                if gse_id not in characteristics_dict:\n",
    "                    characteristics_dict[gse_id] = {}\n",
    "                characteristics_dict[gse_id][gsm_id] = characteristics\n",
    "\n",
    "    # Store the dictionary in a JSON file\n",
    "    with open('data/charateristics_human.json', 'w') as json_file:\n",
    "        json.dump(characteristics_dict, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c1c3df2f-2ee6-4458-a490-2bb0dc3a453d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Scraping GEO Data: 100%|██████████| 100/100 [00:12<00:00,  7.92it/s]\n",
      "Processing GSM Characteristics:   0%|          | 0/100 [00:00<?, ?it/s]/tmp/ipykernel_1597865/3920716366.py:9: DeprecationWarning: The 'text' argument to find()-type methods is deprecated. Use 'string' instead.\n",
      "  characteristics_label = soup.find('td', text='Characteristics')\n",
      "Processing GSM Characteristics: 2446it [03:27, 11.77it/s]                       \n"
     ]
    }
   ],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89b5127-92af-4aef-9232-28b91f0f18c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
